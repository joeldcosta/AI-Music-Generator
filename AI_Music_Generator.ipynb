{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        " ‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà     ‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà ‚ñà‚ñà    ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà    ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  \n",
        "‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà     ‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà    ‚ñà‚ñà ‚ñà‚ñà      ‚ñà‚ñà ‚ñà‚ñà          ‚ñà‚ñà       ‚ñà‚ñà      ‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà      ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà \n",
        "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà     ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà ‚ñà‚ñà    ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà ‚ñà‚ñà          ‚ñà‚ñà   ‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà  ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  \n",
        "‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà     ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà ‚ñà‚ñà    ‚ñà‚ñà      ‚ñà‚ñà ‚ñà‚ñà ‚ñà‚ñà          ‚ñà‚ñà    ‚ñà‚ñà ‚ñà‚ñà      ‚ñà‚ñà  ‚ñà‚ñà ‚ñà‚ñà ‚ñà‚ñà      ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà \n",
        "‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà     ‚ñà‚ñà      ‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà ‚ñà‚ñà   ‚ñà‚ñà    ‚ñà‚ñà     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà   ‚ñà‚ñà \n",
        "                                                                                                                                       \n",
        "                                                                                                                                       \n",
        "```"
      ],
      "metadata": {
        "id": "nPhGLUNsyckX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHJPhnu7Lg2v"
      },
      "source": [
        "# **Mubert Text to Music ‚úç ‚û° üéπüéµüîä**\n",
        "\n",
        "A simple notebook demonstrating prompt-based music generation via [Mubert](https://mubert.com) [API](https://mubert2.docs.apiary.io/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrryqHcOz5GT"
      },
      "source": [
        "# Setup  üéπüéµüîä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Im_ahhrz7pL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Setup Environment**\n",
        "#@markdown **‚úîÔ∏è Install PIP Environment**\n",
        "import subprocess, time\n",
        "print(\"Setting up environment...\")\n",
        "start_time = time.time()\n",
        "all_process = [\n",
        "    ['pip', 'install', 'torch==1.12.1+cu113', 'torchvision==0.13.1+cu113', '--extra-index-url', 'https://download.pytorch.org/whl/cu113'],\n",
        "    ['pip', 'install', '-U', 'sentence-transformers'],\n",
        "    ['pip', 'install', 'httpx'],\n",
        "    ['pip', 'install', 'wget'],\n",
        "]\n",
        "for process in all_process:\n",
        "    running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Environment set up in {end_time-start_time:.0f} seconds\")\n",
        "\n",
        "#@markdown **‚úîÔ∏è Define Mubert methods and pre-compute things**\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "minilm = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "mubert_tags_string = 'tribal,action,kids,neo-classic,run 130,pumped,jazz / funk,ethnic,dubtechno,reggae,acid jazz,liquidfunk,funk,witch house,tech house,underground,artists,mystical,disco,sensorium,r&b,agender,psychedelic trance / psytrance,peaceful,run 140,piano,run 160,setting,meditation,christmas,ambient,horror,cinematic,electro house,idm,bass,minimal,underscore,drums,glitchy,beautiful,technology,tribal house,country pop,jazz & funk,documentary,space,classical,valentines,chillstep,experimental,trap,new jack swing,drama,post-rock,tense,corporate,neutral,happy,analog,funky,spiritual,sberzvuk special,chill hop,dramatic,catchy,holidays,fitness 90,optimistic,orchestra,acid techno,energizing,romantic,minimal house,breaks,hyper pop,warm up,dreamy,dark,urban,microfunk,dub,nu disco,vogue,keys,hardcore,aggressive,indie,electro funk,beauty,relaxing,trance,pop,hiphop,soft,acoustic,chillrave / ethno-house,deep techno,angry,dance,fun,dubstep,tropical,latin pop,heroic,world music,inspirational,uplifting,atmosphere,art,epic,advertising,chillout,scary,spooky,slow ballad,saxophone,summer,erotic,jazzy,energy 100,kara mar,xmas,atmospheric,indie pop,hip-hop,yoga,reggaeton,lounge,travel,running,folk,chillrave & ethno-house,detective,darkambient,chill,fantasy,minimal techno,special,night,tropical house,downtempo,lullaby,meditative,upbeat,glitch hop,fitness,neurofunk,sexual,indie rock,future pop,jazz,cyberpunk,melancholic,happy hardcore,family / kids,synths,electric guitar,comedy,psychedelic trance & psytrance,edm,psychedelic rock,calm,zen,bells,podcast,melodic house,ethnic percussion,nature,heavy,bassline,indie dance,techno,drumnbass,synth pop,vaporwave,sad,8-bit,chillgressive,deep,orchestral,futuristic,hardtechno,nostalgic,big room,sci-fi,tutorial,joyful,pads,minimal 170,drill,ethnic 108,amusing,sleepy ambient,psychill,italo disco,lofi,house,acoustic guitar,bassline house,rock,k-pop,synthwave,deep house,electronica,gabber,nightlife,sport & fitness,road trip,celebration,electro,disco house,electronic'\n",
        "mubert_tags = np.array(mubert_tags_string.split(','))\n",
        "mubert_tags_embeddings = minilm.encode(mubert_tags)\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "import httpx\n",
        "import json\n",
        "import wget\n",
        "from google.colab import files\n",
        "\n",
        "def get_track_by_tags(tags, pat, duration, maxit=20, autoplay=False, loop=False):\n",
        "  if loop:\n",
        "    mode = \"loop\"\n",
        "  else:\n",
        "    mode = \"track\"\n",
        "  r = httpx.post('https://api-b2b.mubert.com/v2/RecordTrackTTM', \n",
        "      json={\n",
        "          \"method\":\"RecordTrackTTM\",\n",
        "          \"params\": {\n",
        "              \"pat\": pat, \n",
        "              \"duration\": duration,\n",
        "              \"tags\": tags,\n",
        "              \"mode\": mode\n",
        "          }\n",
        "      })\n",
        "\n",
        "  rdata = json.loads(r.text)\n",
        "  assert rdata['status'] == 1, rdata['error']['text']\n",
        "  trackurl = rdata['data']['tasks'][0]['download_link']\n",
        "\n",
        "  print('Generating track ', end='')\n",
        "  for i in range(maxit):\n",
        "      r = httpx.get(trackurl)\n",
        "      if r.status_code == 200:\n",
        "          mp = Audio(trackurl, autoplay=autoplay)\n",
        "          mp3 = display(mp)\n",
        "          #Save File##############\n",
        "          time.sleep(3)\n",
        "          wget.download(trackurl)\n",
        "          time.sleep(3)\n",
        "          music_file = trackurl.rsplit(\"/\",)[-1:]\n",
        "          files.download(str(music_file[0]))\n",
        "          print(\"Downloaded!!!\")\n",
        "          ########################\n",
        "          break\n",
        "      time.sleep(1)\n",
        "      print('.', end='')\n",
        "\n",
        "def find_similar(em, embeddings, method='cosine'):\n",
        "    scores = []\n",
        "    for ref in embeddings:\n",
        "        if method == 'cosine': \n",
        "            scores.append(1 - np.dot(ref, em)/(np.linalg.norm(ref)*np.linalg.norm(em)))\n",
        "        if method == 'norm': \n",
        "            scores.append(np.linalg.norm(ref - em))\n",
        "    return np.array(scores), np.argsort(scores)\n",
        "\n",
        "def get_tags_for_prompts(prompts, top_n=3, debug=False):\n",
        "    prompts_embeddings = minilm.encode(prompts)\n",
        "    ret = []\n",
        "    for i, pe in enumerate(prompts_embeddings):\n",
        "        scores, idxs = find_similar(pe, mubert_tags_embeddings)\n",
        "        top_tags = mubert_tags[idxs[:top_n]]\n",
        "        top_prob = 1 - scores[idxs[:top_n]]\n",
        "        if debug:\n",
        "            print(f\"Prompt: {prompts[i]}\\nTags: {', '.join(top_tags)}\\nScores: {top_prob}\\n\\n\\n\")\n",
        "        ret.append((prompts[i], list(top_tags)))\n",
        "    return ret\n",
        "\n",
        "#@markdown **‚úîÔ∏è Get personal access token in Mubert and define API methods**\n",
        "email = \"test@test.com\"\n",
        "\n",
        "r = httpx.post('https://api-b2b.mubert.com/v2/GetServiceAccess', \n",
        "    json={\n",
        "        \"method\":\"GetServiceAccess\",\n",
        "        \"params\": {\n",
        "            \"email\": email,\n",
        "            \"license\":\"ttmmubertlicense#f0acYBenRcfeFpNT4wpYGaTQIyDI4mJGv5MfIhBFz97NXDwDNFHmMRsBSzmGsJwbTpP1A6i07AXcIeAHo5\",\n",
        "            \"token\":\"4951f6428e83172a4f39de05d5b3ab10d58560b8\",\n",
        "            \"mode\": \"loop\"\n",
        "        }\n",
        "    })\n",
        "\n",
        "rdata = json.loads(r.text)\n",
        "assert rdata['status'] == 1, \"probably incorrect e-mail\"\n",
        "pat = rdata['data']['pat']\n",
        "print(f'Got token: {pat}')\n",
        "\n",
        "def generate_track_by_prompt(prompt, duration, loop=False):\n",
        "  _, tags = get_tags_for_prompts([prompt,])[0]\n",
        "  try:\n",
        "    get_track_by_tags(tags, pat, duration, autoplay=True, loop=loop)\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Setup img2text (CLIP Interrogator)**\n",
        "#@markdown **‚úîÔ∏è Install PIP Environment**\n",
        "# install library\n",
        "!pip3 install ftfy regex tqdm transformers==4.15.0 timm==0.4.12 fairscale==0.4.4\n",
        "!pip3 install git+https://github.com/openai/CLIP.git\n",
        "!git clone -b v1 https://github.com/pharmapsychotic/clip-interrogator.git\n",
        "!git clone https://github.com/salesforce/BLIP\n",
        "%cd /content/BLIP\n",
        "\n",
        "\n",
        "# import library\n",
        "import clip\n",
        "import gc\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from models.blip import blip_decoder\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "blip_image_eval_size = 384\n",
        "blip_model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model*_base_caption.pth'        \n",
        "blip_model = blip_decoder(pretrained=blip_model_url, image_size=blip_image_eval_size, vit='base')\n",
        "blip_model.eval()\n",
        "blip_model = blip_model.to(device)\n",
        "\n",
        "\n",
        "# difine function\n",
        "def generate_caption(pil_image):\n",
        "    gpu_image = transforms.Compose([\n",
        "        transforms.Resize((blip_image_eval_size, blip_image_eval_size), interpolation=InterpolationMode.BICUBIC),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "    ])(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        caption = blip_model.generate(gpu_image, sample=False, num_beams=3, max_length=20, min_length=5)\n",
        "    return caption[0]\n",
        "\n",
        "def load_list(filename):\n",
        "    with open(filename, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        items = [line.strip() for line in f.readlines()]\n",
        "    return items\n",
        "\n",
        "def rank(model, image_features, text_array, top_count=1):\n",
        "    top_count = min(top_count, len(text_array))\n",
        "    text_tokens = clip.tokenize([text for text in text_array]).cuda()\n",
        "    with torch.no_grad():\n",
        "        text_features = model.encode_text(text_tokens).float()\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    similarity = torch.zeros((1, len(text_array))).to(device)\n",
        "    for i in range(image_features.shape[0]):\n",
        "        similarity += (100.0 * image_features[i].unsqueeze(0) @ text_features.T).softmax(dim=-1)\n",
        "    similarity /= image_features.shape[0]\n",
        "\n",
        "    top_probs, top_labels = similarity.cpu().topk(top_count, dim=-1)  \n",
        "    return [(text_array[top_labels[0][i].numpy()], (top_probs[0][i].numpy()*100)) for i in range(top_count)]\n",
        "\n",
        "def interrogate(image, models):\n",
        "    caption = generate_caption(image)\n",
        "    if len(models) == 0:\n",
        "        print(f\"\\n\\n{caption}\")\n",
        "        return\n",
        "\n",
        "    table = []\n",
        "    bests = [[('',0)]]*5\n",
        "    for model_name in models:\n",
        "        print(f\"Interrogating with {model_name}...\")\n",
        "        model, preprocess = clip.load(model_name)\n",
        "        model.cuda().eval()\n",
        "\n",
        "        images = preprocess(image).unsqueeze(0).cuda()\n",
        "        with torch.no_grad():\n",
        "            image_features = model.encode_image(images).float()\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        ranks = [\n",
        "            rank(model, image_features, mediums),\n",
        "            rank(model, image_features, [\"by \"+artist for artist in artists]),\n",
        "            rank(model, image_features, trending_list),\n",
        "            rank(model, image_features, movements),\n",
        "            rank(model, image_features, flavors, top_count=3)\n",
        "        ]\n",
        "\n",
        "        for i in range(len(ranks)):\n",
        "            confidence_sum = 0\n",
        "            for ci in range(len(ranks[i])):\n",
        "                confidence_sum += ranks[i][ci][1]\n",
        "            if confidence_sum > sum(bests[i][t][1] for t in range(len(bests[i]))):\n",
        "                bests[i] = ranks[i]\n",
        "\n",
        "        row = [model_name]\n",
        "        for r in ranks:\n",
        "            row.append(', '.join([f\"{x[0]} ({x[1]:0.1f}%)\" for x in r]))\n",
        "\n",
        "        table.append(row)\n",
        "\n",
        "        del model\n",
        "        gc.collect()\n",
        "    display(pd.DataFrame(table, columns=[\"Model\", \"Medium\", \"Artist\", \"Trending\", \"Movement\", \"Flavors\"]))\n",
        "\n",
        "    flaves = ', '.join([f\"{x[0]}\" for x in bests[4]])\n",
        "    medium = bests[0][0][0]\n",
        "    if caption.startswith(medium):\n",
        "        text = f\"{caption} {bests[1][0][0]}, {bests[2][0][0]}, {bests[3][0][0]}, {flaves}\" \n",
        "    else:\n",
        "        text = f\"{caption}, {medium} {bests[1][0][0]}, {bests[2][0][0]}, {bests[3][0][0]}, {flaves}\" \n",
        "    return text\n",
        "\n",
        "\n",
        "# setting\n",
        "data_path = \"../clip-interrogator/data/\"\n",
        "\n",
        "artists = load_list(os.path.join(data_path, 'artists.txt'))\n",
        "flavors = load_list(os.path.join(data_path, 'flavors.txt'))\n",
        "mediums = load_list(os.path.join(data_path, 'mediums.txt'))\n",
        "movements = load_list(os.path.join(data_path, 'movements.txt'))\n",
        "\n",
        "sites = ['Artstation', 'behance', 'cg society', 'cgsociety', 'deviantart', 'dribble', 'flickr', 'instagram', 'pexels', 'pinterest', 'pixabay', 'pixiv', 'polycount', 'reddit', 'shutterstock', 'tumblr', 'unsplash', 'zbrush central']\n",
        "trending_list = [site for site in sites]\n",
        "trending_list.extend([\"trending on \"+site for site in sites])\n",
        "trending_list.extend([\"featured on \"+site for site in sites])\n",
        "trending_list.extend([site+\" contest winner\" for site in sites])\n",
        "\n",
        "\n",
        "# download sample pics\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1Mjwnr_m3pgxTPB7kusePjmKDHktGeV2w', 'pics.zip', quiet=False)\n",
        "! unzip pics.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9q24vakTaDLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7JjxR2E2HVs"
      },
      "source": [
        "# **Here are some prompts to try!!!**\n",
        "cinematic spiritual movie soundtrack star wars type of beat\n",
        "\n",
        "chill hop beats for driving\n",
        "\n",
        "chill hop movie soundtrack beats for studying\n",
        "\n",
        "freestyle r&b hiphop beat\n",
        "\n",
        "jazz & funk for a chill night\n",
        "\n",
        "k-pop music for a anime track\n",
        "\n",
        "meditative peaceful beats\n",
        "\n",
        "psychadelic rock trance for dancing\n",
        "\n",
        "sexual hyper pop \n",
        "\n",
        "techno freestyle for flying\n",
        "\n",
        "electronic dance r&b music nightout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hS8-_sdz8wj"
      },
      "source": [
        "# **Generate some music with prompts üéµ**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Mechanical female android looking, cinematic lighting, intricate, elegant, super highly detailed, art station, concept art, smooth, sharp focus, no blur, no dof, extreme illustration, Unreal Engine 5, Photorealism, HD quality, 8k resolution, cinema 4d, 3D, beautiful, delicate, art by artgerm and greg rutkowski and alphonse mucha and loish and WLOP' #@param {type:\"string\"}\n",
        "#Max 225\n",
        "duration = 225 #@param {type:\"number\"} \n",
        "loop = False #@param {type:\"boolean\"}\n",
        "\n",
        "generate_track_by_prompt(prompt, duration, loop)"
      ],
      "metadata": {
        "id": "Js7jCNnH9DDd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tA6zp2U89QIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image to Music ‚úç ‚û° üñºÔ∏èüéµüîä**"
      ],
      "metadata": {
        "id": "ift7KCsA8vBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Your Own - Test Image (Optional)\n",
        "#@markdown üëà Run Upload from Local Computer\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "def conv_PNG(filename):\n",
        "  im = Image.open(f'{filename}')\n",
        "  im.info.pop('background', None)\n",
        "  file_to_png = filename.split('.')[0]\n",
        "  im.save(f'{file_to_png}.png')\n",
        "  os.rename(f'{file_to_png}.png','/content/BLIP/pics/test_image.png')\n",
        "\n",
        "# upload images\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  conv_PNG(filename)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Bh6zBdM2XD-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OR Please Enter Image URL (Optional)\n",
        "#@markdown üëà Run Upload Test Image Via URL\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "def conv_PNG(filename):\n",
        "  im = Image.open(f'{filename}')\n",
        "  im.info.pop('background', None)\n",
        "  file_to_png = filename.split('.')[0]\n",
        "  im.save(f'{file_to_png}.png')\n",
        "  os.rename(f'{file_to_png}.png','/content/BLIP/pics/test_image.png')\n",
        "\n",
        "#https://media.istockphoto.com/photos/fashion-model-waving-long-fluttering-red-dress-woman-in-garden-white-picture-id1254416379?k=20&m=1254416379&s=612x612&w=0&h=CbcDxBuuKV9FDtdWzEVl_eQFSUl_XfrUjWfGaqJTapY=\n",
        "\n",
        "import requests\n",
        "#url = input(\"Enter Image URL Here:- \") \n",
        "url = \"\" #@param {type:\"string\"}\n",
        "r = requests.get(url)\n",
        "ext = url.rsplit('.', 1)[1]\n",
        "print(ext)\n",
        "\n",
        "try:\n",
        "  with open(f'file.{ext}','wb') as f:\n",
        "    f.write(r.content)\n",
        "except:\n",
        "  with open('file.jpg','wb') as f:\n",
        "    f.write(r.content)\n",
        "\n",
        "try:\n",
        "  conv_PNG(f'file.{ext}')\n",
        "except:\n",
        "  conv_PNG('file.jpg')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XYT89xuoXIVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e9ce3a-6539-4cb9-a7fc-d167578886a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **img2text**\n",
        "#@markdown ##CopyPaste Image Path Here üëá\n",
        "img = \"/content/BLIP/pics/test_image.png\" #@param {type:\"string\"}\n",
        "#image_path ='pics/'+ img\n",
        "image_path = img\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "thumb = image.copy()\n",
        "thumb.thumbnail([blip_image_eval_size, blip_image_eval_size])\n",
        "display(thumb)\n",
        "\n",
        "text = interrogate(image, models=['ViT-L/14'])\n",
        "print('text = ', text)\n",
        "\n",
        "#@title **text2musicüéµ**\n",
        "import time\n",
        "\n",
        "print('text = ', text)\n",
        "prompt = text\n",
        "#@markdown ##Time:- 30 to 225 seconds max üïí\n",
        "duration = 225 #@param {type:\"number\"}\n",
        "loop = False #@param {type:\"boolean\"}\n",
        "\n",
        "def generate_track_by_prompt(prompt, duration, loop=False):\n",
        "  _, tags = get_tags_for_prompts([prompt,])[0]\n",
        "  print('tags = ', tags)\n",
        "  \n",
        "  try:\n",
        "    get_track_by_tags(tags, pat, duration, autoplay=True, loop=loop)\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "  print('\\n')\n",
        "\n",
        "generate_track_by_prompt(prompt, duration, loop)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ByKj5mQG8dQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#::Steps to follow::\n",
        "\n",
        "## For Text to Music\n",
        "- Run Setup Environment\n",
        "- Run Setup img2text\n",
        "- Generate Music using Word Prompts\n",
        "\n",
        "## For Image to Music\n",
        "- Upload your own image. \n",
        "    * It can take any format of Images no issues\n",
        "- From Your computer | OR | from URL \n",
        "    * Note URL should have extension else you will cause an Error\n",
        "    * It can take any format of Images no issues\n",
        "- Run image to text\n",
        "    * By default the path will be in \"BLIP / pic\" folder\n",
        "    * You can add your own path.\n",
        "    * Time duration max is 225 seconds.\n",
        "    * Loop if you want the music to loop.\n",
        "\n",
        "```\n",
        ":::Dev Info:::\n",
        "My Name:- Joel D'costa\n",
        "\n",
        "Any questions regarding this document contact me on twitter \n",
        "i.e. twitter.com/joel_shanky\n",
        "```\n",
        "BLOG:- https://pysnakeblog.blogspot.com/\n"
      ],
      "metadata": {
        "id": "Hbmqih16J5D3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}